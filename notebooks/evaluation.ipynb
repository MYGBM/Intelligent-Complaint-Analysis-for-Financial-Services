{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Pipeline Evaluation ⚖️\n",
    "\n",
    "This notebook evaluates the RAG system by comparing the **Prototype** (small scale, locally embedded) vector store against the **Production** (full scale, pre-embedded) vector store.\n",
    "\n",
    "## Objectives\n",
    "1. **Load Pipelines**: Initialize RAG pipelines for both collections.\n",
    "2. **Define Test Queries**: A set of realistic consumer complaints questions.\n",
    "3. **Run Comparisons**: Query both systems and compare retrieval quality and answers.\n",
    "4. **Qualitative Analysis**: Discuss differences in response quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Add src to path\n",
    "sys.path.append(os.path.abspath(os.path.join('../src')))\n",
    "from rag_pipeline import RAGPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initialize Pipelines\n",
    "\n",
    "We connect to both vector stores. Note that the 'Production' store must have been built using `src/index_production.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VECTOR_DB_PATH = '../vector_store'\n",
    "\n",
    "print(\"Initializing PROTOTYPE Pipeline...\")\n",
    "try:\n",
    "    rag_proto = RAGPipeline(vector_db_path=VECTOR_DB_PATH, collection_name='complaints_prototype')\n",
    "    print(\"Prototype Loaded.\")\n",
    "except Exception as e:\n",
    "    print(f\"Prototype Load Failed: {e}\")\n",
    "    rag_proto = None\n",
    "\n",
    "print(\"\\nInitializing PRODUCTION Pipeline...\")\n",
    "try:\n",
    "    rag_prod = RAGPipeline(vector_db_path=VECTOR_DB_PATH, collection_name='complaints_production')\n",
    "    print(\"Production Loaded.\")\n",
    "except Exception as e:\n",
    "    print(f\"Production Load Failed (Did you run index_production.py?): {e}\")\n",
    "    rag_prod = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test Queries\n",
    "We select 5 distinct questions covering different products and issues."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_queries = [\n",
    "    \"How do consumers complain about credit card late fees?\",\n",
    "    \"What issues are reported regarding mortgage escrow accounts?\",\n",
    "    \"Are there complaints about identity theft in checking accounts?\",\n",
    "    \"What do people say about debt collection harassment?\",\n",
    "    \"How are student loan servicing errors described?\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Comparative Evaluation\n",
    "We run each query against both systems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "for q in test_queries:\n",
    "    row = {\"Question\": q}\n",
    "    \n",
    "    # Prototype\n",
    "    if rag_proto:\n",
    "        ans_proto, docs_proto, _ = rag_proto.query(q, n_results=3)\n",
    "        row[\"Prototype Answer\"] = ans_proto\n",
    "        row[\"Prototype Sources\"] = len(docs_proto)\n",
    "    else:\n",
    "        row[\"Prototype Answer\"] = \"N/A\"\n",
    "\n",
    "    # Production\n",
    "    if rag_prod:\n",
    "        ans_prod, docs_prod, _ = rag_prod.query(q, n_results=3)\n",
    "        row[\"Production Answer\"] = ans_prod\n",
    "        row[\"Production Sources\"] = len(docs_prod)\n",
    "    else:\n",
    "        row[\"Production Answer\"] = \"N/A\"\n",
    "        \n",
    "    results.append(row)\n",
    "\n",
    "eval_df = pd.DataFrame(results)\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "display(eval_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analysis\n",
    "**Hypothesis**:\n",
    "- **Coverage**: The Production index covers 464k documents versus the Prototype's small subset (e.g., 5000). We expect the Production answers to be more comprehensive and citation-rich.\n",
    "- **Latency**: Retrieval speed should be comparable as ChromaDB handles vector search efficiently, though the larger index might be slightly slower without optimization.\n",
    "- **Quality**: Production answers should reference specific details that might not exist in the small prototype sample."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
